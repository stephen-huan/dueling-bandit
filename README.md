# dueling-bandit

Algorithms for the multi-armed bandit and dueling multi-armed bandit problems.

See the following references (not all of these are currently implemented).

1. A. Agarwal, R. Ghuge, and V. Nagarajan, "An Asymptotically
   Optimal Batched Algorithm for the Dueling Bandit Problem."
   arXiv, Sep. 2022. Available: <https://arxiv.org/abs/2209.12108>

2. A. Agarwal, R. Ghuge, and V. Nagarajan, "Batched Dueling Bandits."
   arXiv, Feb. 2022. Available: <https://arxiv.org/abs/2202.10660>

<!-- prettier-ignore -->
3. S. Agrawal and N. Goyal, "Analysis of Thompson Sampling
   for the multi-armed bandit problem." arXiv, Apr.
   2012. Available: <https://arxiv.org/abs/1111.1797>

4. M. Falahatgar, A. Orlitsky, V. Pichapati, and A. T. Suresh, "Maximum
   Selection and Ranking under Noisy Comparisons." arXiv, May 2017. doi:
   [10.48550/arXiv.1705.05366](https://doi.org/10.48550/arXiv.1705.05366).

5. M. Falahatgar, Y. Hao, A. Orlitsky, V. Pichapati, and V.
   Ravindrakumar, "Maxing and Ranking with Few Assumptions," in
   _Advances in Neural Information Processing Systems_, 2017, vol. 30.

6. J. Komiyama, J. Honda, H. Kashima, and H. Nakagawa, "Regret
   Lower Bound and Optimal Algorithm in Dueling Bandit Problem."
   arXiv, Jun. 2015. Available: <https://arxiv.org/abs/1506.02550>

7. J. Komiyama, J. Honda, and H. Nakagawa, "Copeland Dueling Bandit Problem:
   Regret Lower Bound, Optimal Algorithm, and Computationally Efficient
   Algorithm." arXiv, May 2016. Available: <https://arxiv.org/abs/1605.01677>

8. A. Saha and P. Gaillard, "Versatile Dueling Bandits:
   Best-of-both-World Analyses for Online Learning from Preferences."
   arXiv, Feb. 2022. Available: <https://arxiv.org/abs/2202.06694>

9. H. Wu and X. Liu, "Double Thompson Sampling for Dueling Bandits."
   arXiv, Oct. 2016. Available: <https://arxiv.org/abs/1604.07101>

10. Y. Yue and T. Joachims, "Beat the mean bandit," in
    _Proceedings of the 28th International Conference on International
    Conference on Machine Learning_, Jun. 2011, pp. 241â€“248.

11. J. Zimmert and Y. Seldin, "Tsallis-INF: An Optimal
    Algorithm for Stochastic and Adversarial Bandits." arXiv,
    Mar. 2022. Available: <https://arxiv.org/abs/1807.07623>

12. M. Zoghi, Z. Karnin, S. Whiteson, and M. de Rijke,
    "Copeland Dueling Bandits." arXiv, May 2015. doi:
    [10.48550/arXiv.1506.00312](https://doi.org/10.48550/arXiv.1506.00312).
